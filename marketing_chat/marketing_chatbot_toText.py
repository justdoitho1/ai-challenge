from sqlalchemy import create_engine, text, inspect
from sqlalchemy.orm import Session
import sqlalchemy
import boto3 
from botocore.config import Config
import json
import sqlite3
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import io

# -------------------------------------------------------------------------------------
# aws key setting
access_key = ''
secret_key = ''
knowledge_base_id1 = ''
region_name =''
llm_model = ''
model_arn = ''

try:
    with open('./access_key.json', 'r') as f:
        keys = json.load(f)
        access_key = keys.get('access_key', '')
        secret_key = keys.get('secret_key', '')
        knowledge_base_id1 = keys.get('knowledge_base_id1', '')
        region_name =keys.get('region_name', '')
        llm_model = keys.get('llm_model', '')
        model_arn = keys.get('model_arn', '')
    if not access_key or not secret_key:
        raise ValueError("Access key or secret key is missing in access_key.json")

except FileNotFoundError:
    raise FileNotFoundError("access_key.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
except json.JSONDecodeError:
    raise ValueError("access_key.json íŒŒì¼ì˜ í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. JSON í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.")
# -------------------------------------------------------------------------------------

# --------------------------------------------------------------------------------------
# AWS Bedrock ëª¨ë¸ ì´ˆê¸°í™”
# boto3ë¥¼ ì‚¬ìš©í•˜ì—¬ AWS Bedrock ëª¨ë¸(anthropic.claude-3-5-haiku)ì— ì ‘ê·¼í•©ë‹ˆë‹¤.
# init_boto3_client í•¨ìˆ˜ë¡œ Bedrock í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•˜ê³ , converse_with_bedrock í•¨ìˆ˜ë¡œ ëª¨ë¸ê³¼ ëŒ€í™”í•©ë‹ˆë‹¤.
def init_boto3_client(region: str):
    if not access_key or not secret_key:
        raise ValueError("AWS ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    retry_config = Config(
        region_name=region,
        retries={"max_attempts": 10, "mode": "standard"}
    )
    return boto3.client(
        # service_name="bedrock-runtime",
        service_name="bedrock-agent-runtime",
        aws_access_key_id=access_key,
        aws_secret_access_key=secret_key,
        region_name=region,
        config=retry_config
    )
# --------------------------------------------------------------------------------------
# USE KNOWLEDGE_BASE
# --------------------------------------------------------------------------------------
# AWS ë² ë“œë½ ì§€ì‹ê¸°ë°˜ ì—°ê²° : ìì—°ì–´ => SQL ë³€ê²½ 
def converse_with_bedrock_kb(boto3_client, sys_prompt, user_prompt):    
    temperature = 0.0
    top_p = 0.1
    inference_config = {"temperature": temperature, "topP": top_p}
    response = boto3_client.retrieve_and_generate(
    input= {"text": sys_prompt[0]["text"] + user_prompt[0]["content"][0]["text"]+ "\nSkip the preamble and provide only the SQL."},
    retrieveAndGenerateConfiguration={
        "type": "KNOWLEDGE_BASE",  
        "knowledgeBaseConfiguration": {
            "knowledgeBaseId": knowledge_base_id1, # ì§€ì‹ê¸°ë°˜ woongdalsam 
            "modelArn": model_arn, 
        }
    }
)
    return response['output']

# AWS ë² ë“œë½ ì§€ì‹ê¸°ë°˜ ì—°ê²° : SQL => ìì—°ì–´
def natural_answer_from_result_with_kb(boto3_client, prompt_text: str):
    response = boto3_client.retrieve_and_generate(
        input={"text": prompt_text},
        retrieveAndGenerateConfiguration={
            "type": "KNOWLEDGE_BASE",
            "knowledgeBaseConfiguration": {
                "knowledgeBaseId": knowledge_base_id1,
                "modelArn": model_arn,
            }
        }
    )
    return response["output"]["text"]
# --------------------------------------------------------------------------------------

# --------------------------------------------------------------------------------------
# bedrock LLM í†µì‹  í•¨ìˆ˜ 
def converse_with_bedrock(boto3_client, sys_prompt, usr_prompt):    
    temperature = 0.0
    top_p = 0.1
    inference_config = {"temperature": temperature, "topP": top_p}
    
    response = boto3_client.converse(
        modelId=llm_model, 
        messages=usr_prompt, 
        system=sys_prompt,
        inferenceConfig=inference_config
    )

    return response['output']['message']['content'][0]['text']
# --------------------------------------------------------------------------------------

# --------------------------------------------------------------------------------------
# bedrock client ê°€ì ¸ì˜¤ê¸° 
boto3_client = init_boto3_client(region_name)
# -------------------------------------------------------------------------------------

# -------------------------------------------------------------------------------------
# ë°ì´í„°ë² ì´ìŠ¤ì˜ í…Œì´ë¸” ë° ì»¬ëŸ¼ ì •ë³´ë¥¼ ê°€ì ¸ì™€ SQL ì¿¼ë¦¬ ìƒì„±ì„ ìœ„í•œ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
def get_schema_info(db_path):
    engine = create_engine(f'sqlite:///marketing_chat/{db_path}')
    inspector = inspect(engine)
    schema_info = {}
    tables = inspector.get_table_names()
    for table_name in tables:
        columns = inspector.get_columns(table_name)
        table_info = f"Table: {table_name}\n" + "\n".join(f"  - {col['name']} ({col['type']})" for col in columns)
        schema_info[table_name] = table_info
    return schema_info

schema = get_schema_info("./aiChallenge.db")

# -------------------------------------------------------------------------------------
# ì´ë¯¸ì§€ í°íŠ¸ ê²½ë¡œ ì„¤ì •
font_path = './NanumBarunGothic.ttf'
font_name = fm.FontProperties(fname=font_path).get_name()
plt.rc('font', family=font_name)

# -------------------------------------------------------------------------------------
# PROMPT
# -------------------------------------------------------------------------------------
# SYSTEM PROMPT 
dialect = "sqlite"
top_k = 10
table_info = schema['customer'] # í…Œì´ë¸” ì •ë³´ë¥¼ ë‹¤ ê°€ì ¸ì™”ìœ¼ë¯€ë¡œ~ 

sys_prompt = [{
    "text": f"""You are a {dialect} expert.
Given an input question, first create a syntactically correct SQLite query to run. 
Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per SQLite. You can order the results to return the most informative data in the database.
Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (") to denote them as delimited identifiers.
Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.
Pay attention to use date(\'now\') function to get the current date, if the question involves "today" 

Guidelines:
- If values like age are vague (e.g., "mid-30s"), estimate them (e.g., 35).
- If values are missing, use 0 for numbers and "" for text values.
- If the input describes a condition or query, generate a `SELECT` statement.
- If the input describes new data, generate an `INSERT` statement.
- Output only the SQL query. No explanations, comments, or formatting.
- Use standard SQLite syntax.

Only use the following tables:
{table_info}
""" 
}]

# ìœ ì € í”„ë¡¬í”„íŠ¸ returní•˜ëŠ” í•¨ìˆ˜ 
def get_user_prompt(question):
    return [{
        "role": "user",
        "content": [{"text": f"Question:\n{question}]\n\n  Skip the preamble and provide only the SQL" #ì„œë¬¸ ê±´ë„ˆë›°ê³  sqlë§Œ ì œê³µ
        }]
    }]


# sql => ìì—°ì–´ prompt
def sqlToText_prompt(sql_query: str, result) -> str:
    if not result:
        return "ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    return f"""
                SQL ì¿¼ë¦¬:
                {sql_query}

                ê²°ê³¼:
                {result}

                ìœ„ ì¿¼ë¦¬ì™€ ê²°ê³¼ì— ëŒ€í•œ ìì—°ì–´ ì„¤ëª…ì„ í•´ì¤˜. 
                ì˜ˆë¥¼ ë“¤ì–´, í‰ê·  ë‚˜ì´ê°€ 51.5ì„¸ì´ë©´ "ì •ìˆ˜ê¸° ì‚¬ìš©ìì˜ í‰ê·  ë‚˜ì´ëŠ” 51.5ì„¸ì—ìš”." ì™€ ê°™ì€ ì‹ìœ¼ë¡œ ëŒ€ë‹µí•´ì¤˜.
                """


# -------------------------------------------------------------------------------------
# pie ì°¨íŠ¸ ìƒì„± ë° ì´ë¯¸ì§€ ë°”ì´íŠ¸ì½”ë“œ ì¶”ì¶œ
# user_promptì— 'í†µê³„', 'ê·¸ë˜í”„', 'ê·¸ë¦¼'ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
# ratio : ê° ë ˆì´ë¸” ë¹„ìœ¨ / labels : ê° ë ˆì´ë¸” ì´ë¦„
def create_pie_chart(query_result):

    if not query_result or len(query_result) == 0:
        print("ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

    # ê° rowê°€ ìµœì†Œ 2ê°œ ì´ìƒì˜ ê°’ì„ ê°€ì ¸ì•¼ pie chartë¥¼ ê·¸ë¦´ ìˆ˜ ìˆìŒ
    for row in query_result:
        if len(row) < 2:
            print("ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ : ì¿¼ë¦¬ ê²°ê³¼ì˜ ê° í–‰ì´ 2ê°œ ì´ìƒì˜ ê°’ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.")
            return None

    ratio =  [row[1] for row in query_result if len(row) > 0 and row[1] is not None]
    labels = [row[0] for row in query_result if len(row) > 0 and row[0] is not None]

    print("arr1:", ratio)
    print("arr2:", labels)
    plt.figure()
    plt.pie(ratio, labels=labels, autopct='%.1f%%', startangle=260, counterclock=False)
    png_buffer = io.BytesIO()
    plt.savefig(png_buffer, format='png')
    png_bytes = png_buffer.getvalue()
    png_buffer.close()
    print("ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
    plt.show() #todo í…ŒìŠ¤íŠ¸ í›„ ì£¼ì„ í•„ìš” 
    return png_bytes


# -------------------------------------------------------------------------------------
class ChatMessage(): #ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ ë©”ì‹œì§€ë¥¼ ì €ì¥í•  ìˆ˜ ìˆëŠ” í´ë˜ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤.
  def __init__(self, role, message_type, text, bytesio=None, image_bytes=None):
    self.role = role
    self.message_type = message_type
    self.text = text
    self.bytesio = bytesio #used for streamlit rendering
    self.image_bytes = image_bytes #used to pass to the model

# -------------------------------------------------------------------------------------
def chat_with_sql(message_history, new_text=None):
   
    # ì‚¬ìš©ì ìƒí˜¸ì‘ìš© 
    question = new_text
    new_text_message = ChatMessage('user', 'text', text=new_text)
    message_history.append(new_text_message)  

    if any(keyword in question for keyword in ['ë§ì˜í˜', 'ë§ì˜ í˜', 'ìœ¤ì„ê¸ˆ', 'íšŒì¥ë‹˜', 'ë³´ìŠ¤']):
        file_path = './img/boss.jpg'  # ë³´ìŠ¤ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        file_bytes = open(file_path, "rb").read()  # íŒŒì¼ì„ ì½ê¸° ëª¨ë“œë¡œ ì—´ê¸°
        
        response_chart = ChatMessage('assistant', 'image', text="boss", bytesio=file_bytes)
        response_message = ChatMessage('assistant', 'text', "ë‚˜ë¥¼ ì°¾ëŠ”ê°€")
        message_history.append(response_chart)
        message_history.append(response_message)
        return message_history

    if any(keyword in question for keyword in ['swimming', 'ìˆ˜ì˜', 'ì´ìˆ˜ì˜', 'ëŒ€í‘œë‹˜', 'ë¹›']):
        file_path = './img/swimming.jpg'  # ë³´ìŠ¤ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        file_bytes = open(file_path, "rb").read()  # íŒŒì¼ì„ ì½ê¸° ëª¨ë“œë¡œ ì—´ê¸°

        response_chart = ChatMessage('assistant', 'image', text="boss", bytesio=file_bytes)
        response_message = ChatMessage('assistant', 'text', "ì´ëª¸ ë“±ì¥")
        message_history.append(response_chart)
        message_history.append(response_message)
        return message_history

    user_prompt = get_user_prompt(question)

    response = converse_with_bedrock_kb(boto3_client, sys_prompt, user_prompt)
    sql_query = response['text']
    print("ğŸ¤–ì¿¼ë¦¬ë¡œ ì•Œë ¤ë“œë¦´ê²Œìš”.....")
    print(sql_query)

    # -------------------------------------------------------------------------------------
    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¿¼ë¦¬ë¥¼ DBì—ì„œ ì‹¤í–‰ í›„ ê²°ê³¼ ë°˜í™˜ 
    conn = sqlite3.connect("./marketing_chat/aiChallenge.db")
    cur = conn.cursor()

    query_result = cur.execute(sql_query).fetchall()
    print("SQL Query Result:"+str(query_result))

    # sql_query,result ì„ ê¸°ë°˜ìœ¼ë¡œ ìì—°ì–´ ì‘ë‹µ ìƒì„±
    # 1.get sqlToText prompt
    prompt_text = sqlToText_prompt(sql_query, query_result)
    # 2.ìì—°ì–´ prompt & ì§€ì‹ê¸°ë°˜ í™œìš©í•˜ì—¬ ì‘ë‹µê°’ ë°˜í™˜
    natural_answer = natural_answer_from_result_with_kb(boto3_client, prompt_text)
    print("ğŸ¤–ê²°ê³¼ë¥¼ ì•Œë ¤ë“œë¦´ê²Œìš”.....")
    print(natural_answer)
    
    response_message = ChatMessage('assistant', 'text', natural_answer)
    message_history.append(response_message)
    
    #sql, ì¿¼ë¦¬, query í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš° sql ì¶œë ¥
    if any(keyword in question for keyword in ['sql', 'ì¿¼ë¦¬', 'query']):
        response_message = ChatMessage('assistant', 'text', sql_query)
        message_history.append(response_message)

    # 'ë¹„ì¤‘', ë¹„ìœ¨, í†µê³„, ê·¸ë˜í”„, ê·¸ë¦¼ ë“±ì˜ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ : ìˆ˜ì •ê°€ëŠ¥ 
    if any(keyword in question for keyword in ['ë¹„ì¤‘', 'ë¹„ìœ¨', 'í†µê³„', 'ê·¸ë˜í”„', 'ê·¸ë¦¼']):
        chart = create_pie_chart(query_result)
        response_chart = ChatMessage('assistant', 'image', text="ì°¨íŠ¸ ì´ë¯¸ì§€", bytesio=chart)
        message_history.append(response_chart)
    
    return message_history
    # -------------------------------------------------------------------------------------
  