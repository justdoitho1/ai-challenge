import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
from tensorflow import keras
import boto3
import numpy as np
import json
import random

model = None
client = None


# -------------------------------------------------------------------------------------
# aws key setting
access_key = ''
secret_key = ''
flow_identifier = ''
flow_alias_identifier = ''
with open('access_key.json', 'r') as f:
  keys = json.load(f)
  access_key = keys.get('access_key', '')
  secret_key = keys.get('secret_key', '')
  flow_identifier = keys.get('flow_identifier', '')
  flow_alias_identifier = keys.get('flow_alias_identifier', '')
  
  client = boto3.client(
    service_name='bedrock-agent-runtime',
    region_name='us-west-2',
    aws_access_key_id=access_key, # user aws access key
    aws_secret_access_key =secret_key # user aws secret key
  )
  
# -------------------------------------------------------------------------------------
# model ì „ì—­ë³€ìˆ˜ë¡œ ì‚¬ìš©
if tf.io.gfile.exists('product_recommendation_model.h5'):
  model = keras.models.load_model('product_recommendation_model.h5')
# predict  
def model_predict(user_data):
  global model
  prediction = model.predict(user_data)
  return np.argmax(prediction, axis=1)

product_name = {
  0: [ 'ì‹ê¸°ì„¸ì²™ê¸° 1', 'WHITE', 'ì‹±ê¸€ìš©', 'ìš©ëŸ‰ : 4ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 23,000ì›'],
  1: [ 'ì‹ê¸°ì„¸ì²™ê¸° 2', 'PINK', 'ì‹±ê¸€ìš©', 'ìš©ëŸ‰ : 3ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 21,000ì›'],
  2: [ 'ì‹ê¸°ì„¸ì²™ê¸° 3', 'GRAY', '4ì¸ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 8ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 42,000ì›'],
  3: [ 'ì‹ê¸°ì„¸ì²™ê¸° 4', 'PINK', '4ì¸ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 6ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 38,000ì›'],
  4: [ 'ì‹ê¸°ì„¸ì²™ê¸° 5', 'WHITE', '4ì¸ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 10ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 47,000ì›'],
  5: [ 'ì‹ê¸°ì„¸ì²™ê¸° 6', 'WHITE', '4ì¸ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 8ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 43,000ì›'],
  6: [ 'ì‹ê¸°ì„¸ì²™ê¸° 7', 'BLACK', '4ì¸ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 10ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 40,000ì›'],
  7: [ 'ì‹ê¸°ì„¸ì²™ê¸° 8', 'BLACK', 'ëŒ€ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 16ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 55,000ì›'],
  8: [ 'ì‹ê¸°ì„¸ì²™ê¸° 9', 'YELLOW', 'ëŒ€ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 14ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 58,000ì›'],
  9: ['ì‹ê¸°ì„¸ì²™ê¸° 10', 'GRAY', 'ëŒ€ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 18ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 62,000ì›'],
}
# product_name = {
#   0: [ 'ì‹ê¸°ì„¸ì²™ê¸° 1', 'WHITE', 'ì‹±ê¸€ìš©', 'ìš©ëŸ‰ : 4ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 23,000ì›'],
#   1: [ 'ì‹ê¸°ì„¸ì²™ê¸° 2', 'PINK', 'ì‹±ê¸€ìš©', 'ìš©ëŸ‰ : 3ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 21,000ì›'],
#   2: [ 'ì •ìˆ˜ê¸° 3', 'GRAY', '4ì¸ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 8ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 42,000ì›'],
#   3: [ 'ì •ìˆ˜ê¸° 4', 'PINK', '4ì¸ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 6ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 38,000ì›'],
#   4: [ 'ì •ìˆ˜ê¸° 5', 'WHITE', '4ì¸ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 10ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 47,000ì›'],
#   5: [ 'ì •ìˆ˜ê¸° 6', 'WHITE', '4ì¸ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 8ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 43,000ì›'],
#   6: [ 'ì •ìˆ˜ê¸° 7', 'BLACK', '4ì¸ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 10ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 40,000ì›'],
#   7: [ 'ì •ìˆ˜ê¸° 8', 'BLACK', 'ëŒ€ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 16ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 55,000ì›'],
#   8: [ 'ì •ìˆ˜ê¸° 9', 'YELLOW', 'ëŒ€ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 14ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 58,000ì›'],
#   9: ['ì •ìˆ˜ê¸° 10', 'GRAY', 'ëŒ€ê°€ì¡±ìš©', 'ìš©ëŸ‰ : 18ì¸ë¶„', 'ë Œíƒˆë¹„ìš© : 62,000ì›'],
# }
product_img = {
  0: './img/white_1.jpg',
  1: './img/pink_1.jpg',
  2: './img/gray_1.jpg',
  3: './img/pink_2.jpg',
  4: './img/white_2.jpg',
  5: './img/white_3.jpg',
  6: './img/black_1.jpg',
  7: './img/black_2.jpg',
  8: './img/yellow_1.jpg',
  9: './img/gray_2.jpg',
}

#ë””ìŠ¤í¬ì˜ íŒŒì¼ì—ì„œ ë°”ì´íŠ¸ ë¡œë“œí•˜ê¸°
def get_bytes_from_file(file_path):
  with open(file_path, "rb") as image_file:
      file_bytes = image_file.read()
  return file_bytes

class ChatMessage(): #ì´ë¯¸ì§€ ë° í…ìŠ¤íŠ¸ ë©”ì‹œì§€ë¥¼ ì €ì¥í•  ìˆ˜ ìˆëŠ” í´ë˜ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤.
  def __init__(self, role, message_type, text, bytesio=None, image_bytes=None):
    self.role = role
    self.message_type = message_type
    self.text = text
    self.bytesio = bytesio #used for streamlit rendering
    self.image_bytes = image_bytes #used to pass to the model

def chat_with_model(message_history, new_text=None):
  if client is None:
    raise ValueError("AWS client is not initialized. Please check your AWS credentials and configuration.")  
# ì‚¬ìš©ì ì…ë ¥ë¶€ë¶„(ì±—ë´‡ input) -------------------------------------------------------------------
  question = new_text
  print("ì§ˆë¬¸:", question)
  # new_text_message = ChatMessage('user', 'text', text=new_text)
  # message_history.append(new_text_message)  
  
  response = client.invoke_flow(
    flowIdentifier=flow_identifier,
    flowAliasIdentifier=flow_alias_identifier,
    inputs=[
      {
        "content": {
          "document": question
        },
        "nodeName": "FlowInputNode",
        "nodeOutputName": "document"
      }
    ]
  )
  
  # ëª¨ë¸ ì¶œë ¥ë¶€ë¶„(ì±—ë´‡ output) -------------------------------------------------------------------
  result = {}

  for event in response.get("responseStream"):
    result.update(event)
  '''
  expect output format
    ```json
    {
      "output_data": [
        45,
        7,
        40,
        14,
        85,
        7
      ]
    }
    ```
  '''
  # parsing
  res = result['flowOutputEvent']['content']['document'].replace('`', '').replace('json', '')
  
  # json ë¬¸ìì—´ì„ ì‹¤ì œ json ê°ì²´ë¡œ ë³€í™˜
  try:
    res_json = json.loads(res)
    if 'output_data' in res_json:
      output_data = res_json['output_data']
      if len(output_data) == 6:
        # 'ë‚˜ì´', 'ê°€ì¡± ìˆ˜', 'ë Œíƒˆë¹„ìš©(ì²œì›)', 'ìš©ëŸ‰', 'ë§Œì¡±ë„', 'í• ì¸ìœ¨'
        if(output_data[0] is None or output_data[0] == 0):
          output_data[0] = random.randint(23, 70)  # ë‚˜ì´
        if(output_data[4] is None or output_data[4] == 0):
          output_data[4] = random.randint(70, 95)
        if(output_data[5] is None or output_data[5] == 0):
          output_data[5] = random.randint(5, 10)
          
        user_data = np.array([output_data])
        pred_idx = model_predict(user_data.astype(int))
        result = product_name[pred_idx[0]]
        msg = "ì´ ì œí’ˆì„ ì¶”ì²œë“œë ¤ìš” : " + str(result)

        print("ì´ ì œí’ˆì„ ì¶”ì²œë“œë ¤ìš” : {}".format(product_name[pred_idx[0]]))
        response_message = ChatMessage('assistant', 'text', msg)
        
        img_bytes = get_bytes_from_file(product_img[pred_idx[0]])
        
        response_img = ChatMessage('assistant', 'image', text="ì¶”ì²œ ì œí’ˆ ì´ë¯¸ì§€", bytesio=img_bytes)
        message_history.append(response_message)
        message_history.append(response_img)

        return message_history

      else:
        print("output_dataì˜ ê¸¸ì´ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆìƒ ê¸¸ì´: 6, ì‹¤ì œ ê¸¸ì´: ".format(len(output_data)))
        response_message = ChatMessage('assistant', 'text', "ë‹¬ìƒ˜ì´ê°€ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.ğŸ˜­")
        return message_history.append(response_message)

    else:
      print("output_data í‚¤ê°€ JSONì— ì—†ìŠµë‹ˆë‹¤.")
      response_message = ChatMessage('assistant', 'text', "ë‹¬ìƒ˜ì´ê°€ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.ğŸ˜­")
      return message_history.append(response_message)
  except Exception as e:
    print("ì˜¤ë¥˜ë°œìƒ :", e)
    response_message = ChatMessage('assistant', 'text', "ë‹¬ìƒ˜ì´ê°€ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.ğŸ˜­")
    return message_history.append(response_message)

# -------------------------------------------------------------------------------------

'''
if tf.io.gfile.exists('product_recommendation_model.h5'):
  model = keras.models.load_model('product_recommendation_model.h5')
  while True:
    # ì‚¬ìš©ì ì…ë ¥ë¶€ë¶„(ì±—ë´‡ input) -------------------------------------------------------------------
    question = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. ì¢…ë£Œí•˜ê³  ì‹¶ìœ¼ì‹œë©´ exitë¥¼ ì…ë ¥í•˜ì„¸ìš”. : ")
    if question.lower() == 'exit':
      break
    client = boto3.client(
      service_name='bedrock-agent-runtime',
      region_name='us-west-2',
      aws_access_key_id=access_key, # user aws access key
      aws_secret_access_key =secret_key # user aws secret key
    )
    response = client.invoke_flow(
      flowIdentifier=flow_identifier,
      flowAliasIdentifier=flow_alias_identifier,
      inputs=[
        {
          "content": {
            "document": question
          },
          "nodeName": "FlowInputNode",
          "nodeOutputName": "document"
        }
      ]
    )
    
    # ëª¨ë¸ ì¶œë ¥ë¶€ë¶„(ì±—ë´‡ output) -------------------------------------------------------------------
    result = {}

    for event in response.get("responseStream"):
      result.update(event)
    # expect output format
    #   ```json
    #   {
    #     "output_data": [
    #       45,
    #       7,
    #       40,
    #       14,
    #       85,
    #       7
    #     ]
    #   }
    #   ```
    # parsing
    res = result['flowOutputEvent']['content']['document'].replace('`', '').replace('json', '')
    
    # json ë¬¸ìì—´ì„ ì‹¤ì œ json ê°ì²´ë¡œ ë³€í™˜
    try:
      res_json = json.loads(res)
      if 'output_data' in res_json:
        output_data = res_json['output_data']
        if len(output_data) == 6:
          # 'ë‚˜ì´', 'ê°€ì¡± ìˆ˜', 'ë Œíƒˆë¹„ìš©(ì²œì›)', 'ìš©ëŸ‰', 'ë§Œì¡±ë„', 'í• ì¸ìœ¨'
          if(output_data[0] is None or output_data[0] == 0):
            output_data[0] = random.randint(23, 70)  # ë‚˜ì´
          if(output_data[4] is None or output_data[4] == 0):
            output_data[4] = random.randint(70, 95)
          if(output_data[5] is None or output_data[5] == 0):
            output_data[5] = random.randint(5, 10)
            
          print("output_data:", output_data)
          user_data = np.array([output_data])
          pred_idx = model_predict(user_data.astype(int))
          print("ì´ ì œí’ˆì„ ì¶”ì²œë“œë ¤ìš” : {}".format(product_name[pred_idx[0]]))
        else:
          print("output_dataì˜ ê¸¸ì´ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜ˆìƒ ê¸¸ì´: 6, ì‹¤ì œ ê¸¸ì´: {}".format(len(output_data)))
      else:
        print("output_data í‚¤ê°€ JSONì— ì—†ìŠµë‹ˆë‹¤.")
    except json.JSONDecodeError as e:
      print("JSON íŒŒì‹± ì˜¤ë¥˜:", e)
      
'''